{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Повнозв'язані нейронні мережі\n",
    "Вирішіть завдання класифікації даних, з якими ви працювали в лабораторній № 1 за допомогою повнозв’язаної нейромережі прямого поширення (fully connected feed-forward network). Результати порівняйте з одержаними раніше. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philip/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
       "0   40   M           ATA        140          289          0     Normal    172   \n",
       "1   49   F           NAP        160          180          0     Normal    156   \n",
       "2   37   M           ATA        130          283          0         ST     98   \n",
       "3   48   F           ASY        138          214          0     Normal    108   \n",
       "4   54   M           NAP        150          195          0     Normal    122   \n",
       "\n",
       "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "0              N      0.0       Up             0  \n",
       "1              N      1.0     Flat             1  \n",
       "2              N      0.0       Up             0  \n",
       "3              Y      1.5     Flat             1  \n",
       "4              N      0.0       Up             0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "data = pd.read_csv('heart.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((642, 15), (276, 15), (642,), (276,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding для категоріальних змінних\n",
    "categorical_columns = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Нормалізація числових ознак\n",
    "numerical_columns = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']\n",
    "scaler = StandardScaler()\n",
    "data_encoded[numerical_columns] = scaler.fit_transform(data_encoded[numerical_columns])\n",
    "\n",
    "# Відокремлення ознак та цільової змінної\n",
    "X = data_encoded.drop(columns=['HeartDisease'])\n",
    "y = data_encoded['HeartDisease']\n",
    "\n",
    "# Розділення на навчальну і тестову вибірки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Перегляд розмірів вибірок\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Навчальна вибірка містить 642 зразки, тестова — 276. Всього використовується 15 ознак для передбачення наявності серцевих захворювань."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philip/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5110 - loss: 0.7389 - val_accuracy: 0.7319 - val_loss: 0.5715\n",
      "Epoch 2/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6797 - loss: 0.5923 - val_accuracy: 0.8080 - val_loss: 0.5075\n",
      "Epoch 3/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7438 - loss: 0.5439 - val_accuracy: 0.8514 - val_loss: 0.4579\n",
      "Epoch 4/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7798 - loss: 0.4978 - val_accuracy: 0.8514 - val_loss: 0.4117\n",
      "Epoch 5/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8055 - loss: 0.4662 - val_accuracy: 0.8551 - val_loss: 0.3795\n",
      "Epoch 6/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8196 - loss: 0.4539 - val_accuracy: 0.8587 - val_loss: 0.3592\n",
      "Epoch 7/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.4263 - val_accuracy: 0.8587 - val_loss: 0.3477\n",
      "Epoch 8/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7996 - loss: 0.4414 - val_accuracy: 0.8623 - val_loss: 0.3380\n",
      "Epoch 9/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8156 - loss: 0.4005 - val_accuracy: 0.8696 - val_loss: 0.3319\n",
      "Epoch 10/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8532 - loss: 0.3548 - val_accuracy: 0.8696 - val_loss: 0.3288\n",
      "Epoch 11/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8345 - loss: 0.3956 - val_accuracy: 0.8732 - val_loss: 0.3253\n",
      "Epoch 12/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8424 - loss: 0.3641 - val_accuracy: 0.8841 - val_loss: 0.3226\n",
      "Epoch 13/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8528 - loss: 0.3459 - val_accuracy: 0.8841 - val_loss: 0.3199\n",
      "Epoch 14/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8497 - loss: 0.3770 - val_accuracy: 0.8841 - val_loss: 0.3202\n",
      "Epoch 15/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8587 - loss: 0.3640 - val_accuracy: 0.8877 - val_loss: 0.3173\n",
      "Epoch 16/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.3657 - val_accuracy: 0.8913 - val_loss: 0.3151\n",
      "Epoch 17/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8491 - loss: 0.3909 - val_accuracy: 0.8949 - val_loss: 0.3110\n",
      "Epoch 18/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8537 - loss: 0.3542 - val_accuracy: 0.8913 - val_loss: 0.3108\n",
      "Epoch 19/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8265 - loss: 0.3731 - val_accuracy: 0.8949 - val_loss: 0.3111\n",
      "Epoch 20/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8150 - loss: 0.3854 - val_accuracy: 0.8913 - val_loss: 0.3125\n",
      "Epoch 21/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8393 - loss: 0.3728 - val_accuracy: 0.8986 - val_loss: 0.3119\n",
      "Epoch 22/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8461 - loss: 0.3469 - val_accuracy: 0.8986 - val_loss: 0.3099\n",
      "Epoch 23/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8330 - loss: 0.3840 - val_accuracy: 0.8986 - val_loss: 0.3064\n",
      "Epoch 24/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8472 - loss: 0.3378 - val_accuracy: 0.8986 - val_loss: 0.3052\n",
      "Epoch 25/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8310 - loss: 0.3760 - val_accuracy: 0.8949 - val_loss: 0.3078\n",
      "Epoch 26/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8547 - loss: 0.3280 - val_accuracy: 0.9022 - val_loss: 0.3035\n",
      "Epoch 27/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8638 - loss: 0.3264 - val_accuracy: 0.8986 - val_loss: 0.3002\n",
      "Epoch 28/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8517 - loss: 0.3411 - val_accuracy: 0.8986 - val_loss: 0.3022\n",
      "Epoch 29/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8829 - loss: 0.3148 - val_accuracy: 0.8986 - val_loss: 0.3020\n",
      "Epoch 30/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8555 - loss: 0.3500 - val_accuracy: 0.8913 - val_loss: 0.3001\n",
      "Epoch 31/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8597 - loss: 0.3338 - val_accuracy: 0.8949 - val_loss: 0.3005\n",
      "Epoch 32/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8703 - loss: 0.3300 - val_accuracy: 0.8949 - val_loss: 0.3014\n",
      "Epoch 33/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8527 - loss: 0.3273 - val_accuracy: 0.8949 - val_loss: 0.3007\n",
      "Epoch 34/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8363 - loss: 0.3574 - val_accuracy: 0.9022 - val_loss: 0.2987\n",
      "Epoch 35/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8731 - loss: 0.3252 - val_accuracy: 0.8949 - val_loss: 0.2944\n",
      "Epoch 36/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8676 - loss: 0.3094 - val_accuracy: 0.8986 - val_loss: 0.2923\n",
      "Epoch 37/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8787 - loss: 0.2985 - val_accuracy: 0.9058 - val_loss: 0.2966\n",
      "Epoch 38/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8460 - loss: 0.3426 - val_accuracy: 0.9022 - val_loss: 0.2912\n",
      "Epoch 39/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8382 - loss: 0.3455 - val_accuracy: 0.9022 - val_loss: 0.2904\n",
      "Epoch 40/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8733 - loss: 0.3034 - val_accuracy: 0.8949 - val_loss: 0.2907\n",
      "Epoch 41/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8760 - loss: 0.2844 - val_accuracy: 0.8877 - val_loss: 0.2912\n",
      "Epoch 42/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8618 - loss: 0.3228 - val_accuracy: 0.8877 - val_loss: 0.2923\n",
      "Epoch 43/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8511 - loss: 0.2992 - val_accuracy: 0.8913 - val_loss: 0.2900\n",
      "Epoch 44/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8541 - loss: 0.3286 - val_accuracy: 0.8804 - val_loss: 0.2909\n",
      "Epoch 45/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8656 - loss: 0.3441 - val_accuracy: 0.8768 - val_loss: 0.2943\n",
      "Epoch 46/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8706 - loss: 0.3252 - val_accuracy: 0.8841 - val_loss: 0.2905\n",
      "Epoch 47/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8856 - loss: 0.2897 - val_accuracy: 0.8804 - val_loss: 0.2907\n",
      "Epoch 48/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8486 - loss: 0.3354 - val_accuracy: 0.8804 - val_loss: 0.2884\n",
      "Epoch 49/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8919 - loss: 0.2751 - val_accuracy: 0.8949 - val_loss: 0.2875\n",
      "Epoch 50/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8753 - loss: 0.2853 - val_accuracy: 0.8877 - val_loss: 0.2884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2884049713611603, 0.8876811861991882)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Побудова повнозв'язаної нейронної мережі\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')  # Для бінарної класифікації\n",
    "])\n",
    "\n",
    "# Компіляція моделі\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Навчання моделі\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=16, verbose=1)\n",
    "\n",
    "# Оцінка моделі на тестовій вибірці\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "test_loss, test_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У порівнянні з, наприклад, Random Forest з лабораторної №1, точність моделі нейронної мережі така ж сама (88.76%). Пповнозв’язана нейронна мережа так само справляється з цим завданням класифікації."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Згорткові нейронні мережі\n",
    "Вирішіть завдання класифікації зображень за допомогою згорткової (convolutional) нейромережі двома способами\n",
    "а) навчить мережу з нуля (from scratch)\n",
    "б) застосуйте перенесення навчання (transfer learning from pre-trained weights)\n",
    "\n",
    "Порівняйте результати (якщо в обраному датасеті класів забагато, достатньо залишити 3-5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 264ms/step - accuracy: 0.5245 - loss: 0.7605 - val_accuracy: 0.5530 - val_loss: 0.6848\n",
      "Epoch 2/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 341ms/step - accuracy: 0.5921 - loss: 0.6652 - val_accuracy: 0.6720 - val_loss: 0.6255\n",
      "Epoch 3/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 366ms/step - accuracy: 0.6704 - loss: 0.6190 - val_accuracy: 0.7120 - val_loss: 0.5773\n",
      "Epoch 4/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 431ms/step - accuracy: 0.7119 - loss: 0.5521 - val_accuracy: 0.7030 - val_loss: 0.5890\n",
      "Epoch 5/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 427ms/step - accuracy: 0.7476 - loss: 0.5102 - val_accuracy: 0.7000 - val_loss: 0.5846\n",
      "Epoch 6/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 430ms/step - accuracy: 0.7793 - loss: 0.4616 - val_accuracy: 0.7440 - val_loss: 0.5680\n",
      "Epoch 7/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 457ms/step - accuracy: 0.8412 - loss: 0.3573 - val_accuracy: 0.7350 - val_loss: 0.5789\n",
      "Epoch 8/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 437ms/step - accuracy: 0.8707 - loss: 0.2861 - val_accuracy: 0.7430 - val_loss: 0.6119\n",
      "Epoch 9/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 409ms/step - accuracy: 0.8943 - loss: 0.2459 - val_accuracy: 0.7180 - val_loss: 0.7473\n",
      "Epoch 10/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 288ms/step - accuracy: 0.9240 - loss: 0.1823 - val_accuracy: 0.6910 - val_loss: 0.7880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cq/lfznn8xn74x1ygrn_30hqgkm0000gn/T/ipykernel_89826/2913628136.py:61: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(input_shape=(img_height, img_width, 3), include_top=False, weights='imagenet')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 223ms/step - accuracy: 0.8781 - loss: 1.6041 - val_accuracy: 0.9580 - val_loss: 0.5416\n",
      "Epoch 2/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 238ms/step - accuracy: 0.9609 - loss: 0.3215 - val_accuracy: 0.9430 - val_loss: 0.1689\n",
      "Epoch 3/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 303ms/step - accuracy: 0.9736 - loss: 0.0712 - val_accuracy: 0.9520 - val_loss: 0.1520\n",
      "Epoch 4/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 242ms/step - accuracy: 0.9766 - loss: 0.0888 - val_accuracy: 0.9440 - val_loss: 0.1728\n",
      "Epoch 5/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 285ms/step - accuracy: 0.9790 - loss: 0.0639 - val_accuracy: 0.9500 - val_loss: 0.1657\n",
      "Epoch 6/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 287ms/step - accuracy: 0.9856 - loss: 0.0469 - val_accuracy: 0.9570 - val_loss: 0.1860\n",
      "Epoch 7/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 269ms/step - accuracy: 0.9859 - loss: 0.0395 - val_accuracy: 0.9530 - val_loss: 0.1877\n",
      "Epoch 8/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 288ms/step - accuracy: 0.9875 - loss: 0.0286 - val_accuracy: 0.9580 - val_loss: 0.1976\n",
      "Epoch 9/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.9902 - loss: 0.0331 - val_accuracy: 0.9530 - val_loss: 0.2087\n",
      "Epoch 10/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 284ms/step - accuracy: 0.9843 - loss: 0.0386 - val_accuracy: 0.9510 - val_loss: 0.2717\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.7061 - loss: 0.7364 \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 146ms/step - accuracy: 0.9605 - loss: 0.2109\n",
      "Навчання з нуля, точність = 0.6909999847412109\n",
      "Перенесене навчання, точність = 0.9509999752044678\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "\n",
    "# Cats vs Dogs\n",
    "data_dir = tf.keras.utils.get_file(\n",
    "    'cats_and_dogs',\n",
    "    'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip',\n",
    "    extract=True)  # Завантаження та автоматичне розпакування архіву\n",
    "data_dir = os.path.join(os.path.dirname(data_dir), 'cats_and_dogs/cats_and_dogs_filtered')\n",
    "train_dir = f\"{data_dir}/train\"\n",
    "validation_dir = f\"{data_dir}/validation\"\n",
    "\n",
    "# Параметри для обробки зображень\n",
    "batch_size = 32  # Кількість зображень у кожному пакеті\n",
    "img_height = 150  # Висота зображення\n",
    "img_width = 150  # Ширина зображення\n",
    "\n",
    "# Генератори даних із нормалізацією значень пікселів\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0)  # Нормалізація значень до діапазону [0, 1]\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Генерація даних для тренувального набору\n",
    "train_ds = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),  # Зміна розміру зображень\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'  # Цільова змінна є бінарною (cat/dog)\n",
    ")\n",
    "\n",
    "# Генерація даних для тестового набору\n",
    "val_ds = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Навчання моделі з нуля\n",
    "model_scratch = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),  # Перший згортковий шар\n",
    "    MaxPooling2D(),  # Зменшення розмірності\n",
    "    Conv2D(64, (3, 3), activation='relu'),  # Другий згортковий шар\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(128, (3, 3), activation='relu'),  # Третій згортковий шар\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),  # Розгортання в один вектор\n",
    "    Dense(128, activation='relu'),  # Повнозв’язаний шар\n",
    "    Dropout(0.5),  # Регуляризація\n",
    "    Dense(1, activation='sigmoid')  # Вихідний шар для бінарної класифікації\n",
    "])\n",
    "\n",
    "# Компіляція моделі з оптимізатором Adam\n",
    "model_scratch.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Навчання моделі\n",
    "history_scratch = model_scratch.fit(train_ds, validation_data=val_ds, epochs=10)\n",
    "\n",
    "# Перенесення навчання\n",
    "base_model = MobileNetV2(input_shape=(img_height, img_width, 3), include_top=False, weights='imagenet')  # Використання попередньо навченої моделі\n",
    "base_model.trainable = False  # Замороження ваг базової моделі\n",
    "\n",
    "# Додавання нових шарів\n",
    "x = Flatten()(base_model.output)  # Розгортання\n",
    "x = Dense(128, activation='relu')(x)  # Новий повнозв’язаний шар\n",
    "x = Dropout(0.5)(x)  # Регуляризація\n",
    "output = Dense(1, activation='sigmoid')(x)  # Вихідний шар для бінарної класифікації\n",
    "model_transfer = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Компіляція моделі з перенесеним навчанням\n",
    "model_transfer.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Навчання моделі\n",
    "history_transfer = model_transfer.fit(train_ds, validation_data=val_ds, epochs=10)\n",
    "\n",
    "# Оцінка обох моделей\n",
    "loss_scratch, acc_scratch = model_scratch.evaluate(val_ds)  # Оцінка моделі, навченої з нуля\n",
    "loss_transfer, acc_transfer = model_transfer.evaluate(val_ds)  # Оцінка моделі з перенесеним навчанням\n",
    "\n",
    "print(f\"Навчання з нуля, точність = {acc_scratch}\")\n",
    "print(f\"Перенесене навчання, точність = {acc_transfer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У випадку навчання з нуля точність моделі поступово зростала протягом 10 епох, досягнувши максимуму в 69.1% на тестовій вибірці. Незважаючи на стабільне зменшення втрат на тренувальній вибірці, модель показала менш стабільну продуктивність на валідаційних даних.\n",
    "\n",
    "Але модель із використанням перенесеного навчання (на основі MobileNetV2) показує значно вищу точність — 95.1% на тестовій вибірці. Завдяки вже навченим базовим вагам, модель швидко досягла високої результативності з низькими втратами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philip/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 53ms/step - accuracy: 0.7970 - loss: 0.5324 - val_accuracy: 0.9597 - val_loss: 0.1528\n",
      "Epoch 2/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 55ms/step - accuracy: 0.9756 - loss: 0.0995 - val_accuracy: 0.9609 - val_loss: 0.1442\n",
      "Epoch 3/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 59ms/step - accuracy: 0.9842 - loss: 0.0616 - val_accuracy: 0.9591 - val_loss: 0.1585\n",
      "Epoch 4/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 61ms/step - accuracy: 0.9904 - loss: 0.0367 - val_accuracy: 0.9621 - val_loss: 0.1639\n",
      "Epoch 5/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 54ms/step - accuracy: 0.9910 - loss: 0.0306 - val_accuracy: 0.9668 - val_loss: 0.1494\n",
      "Epoch 6/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 53ms/step - accuracy: 0.9933 - loss: 0.0243 - val_accuracy: 0.9690 - val_loss: 0.1778\n",
      "Epoch 7/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 54ms/step - accuracy: 0.9952 - loss: 0.0176 - val_accuracy: 0.9669 - val_loss: 0.1876\n",
      "Epoch 8/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 53ms/step - accuracy: 0.9945 - loss: 0.0159 - val_accuracy: 0.9712 - val_loss: 0.1899\n",
      "Epoch 9/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 53ms/step - accuracy: 0.9961 - loss: 0.0127 - val_accuracy: 0.9658 - val_loss: 0.1832\n",
      "Epoch 10/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 53ms/step - accuracy: 0.9962 - loss: 0.0133 - val_accuracy: 0.9707 - val_loss: 0.1930\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philip/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822us/step - accuracy: 0.7603 - loss: 0.6606 - val_accuracy: 0.8995 - val_loss: 0.3264\n",
      "Epoch 2/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752us/step - accuracy: 0.8922 - loss: 0.3606 - val_accuracy: 0.9040 - val_loss: 0.3051\n",
      "Epoch 3/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - accuracy: 0.8991 - loss: 0.3397 - val_accuracy: 0.9086 - val_loss: 0.2959\n",
      "Epoch 4/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752us/step - accuracy: 0.9031 - loss: 0.3279 - val_accuracy: 0.9082 - val_loss: 0.2933\n",
      "Epoch 5/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.9055 - loss: 0.3298 - val_accuracy: 0.9134 - val_loss: 0.2840\n",
      "Epoch 6/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 751us/step - accuracy: 0.9068 - loss: 0.3115 - val_accuracy: 0.9151 - val_loss: 0.2758\n",
      "Epoch 7/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - accuracy: 0.9094 - loss: 0.3052 - val_accuracy: 0.9170 - val_loss: 0.2715\n",
      "Epoch 8/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 756us/step - accuracy: 0.9135 - loss: 0.2932 - val_accuracy: 0.9192 - val_loss: 0.2660\n",
      "Epoch 9/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - accuracy: 0.9141 - loss: 0.2931 - val_accuracy: 0.9220 - val_loss: 0.2609\n",
      "Epoch 10/10\n",
      "\u001b[1m1103/1103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - accuracy: 0.9146 - loss: 0.2864 - val_accuracy: 0.9211 - val_loss: 0.2641\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.9710 - loss: 0.1909\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - accuracy: 0.9193 - loss: 0.2699\n",
      "Навчання з нуля: точність = 0.9707165360450745\n",
      "Перенесене навчання з tensorflow_hub embeddings: точність = 0.9210734963417053\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Завантаження даних\n",
    "data = pd.read_csv('ecommerceDataset.csv')\n",
    "\n",
    "# Перейменування колонок для зручності\n",
    "data.columns = ['Category', 'Description']\n",
    "\n",
    "# Видалення HTML-розмітки, пунктуації та очищення тексту\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'<.*?>', '', text)  # Видалення HTML\n",
    "    text = text.lower()  # Приведення до нижнього регістру\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Видалення пунктуації\n",
    "    return text\n",
    "\n",
    "data['Cleaned_Description'] = data['Description'].astype(str).apply(preprocess_text)\n",
    "\n",
    "# Кодування міток класів\n",
    "encoder = LabelEncoder()\n",
    "data['Encoded_Category'] = encoder.fit_transform(data['Category'])\n",
    "\n",
    "# Розділення даних\n",
    "X = data['Cleaned_Description']\n",
    "y = data['Encoded_Category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Токенізація текстів\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Паддінг для вирівнювання довжини\n",
    "max_len = 100\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n",
    "\n",
    "# Навчання з нуля \n",
    "vocab_size = 10000\n",
    "embedding_dim = 100\n",
    "\n",
    "model_scratch = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len),\n",
    "    Bidirectional(LSTM(64, return_sequences=False)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "model_scratch.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_scratch = model_scratch.fit(X_train_padded, y_train, validation_data=(X_test_padded, y_test), epochs=10, batch_size=32)\n",
    "\n",
    "# Перенесене навчання з embeddings\n",
    "embed = hub.load('https://tfhub.dev/google/nnlm-en-dim50/2')\n",
    "\n",
    "# Перетворення текстів у вектори \n",
    "def embed_texts(texts):\n",
    "    return np.array([embed([text]).numpy().flatten() for text in texts])\n",
    "\n",
    "X_train_embedded = embed_texts(X_train)\n",
    "X_test_embedded = embed_texts(X_test)\n",
    "\n",
    "model_hub = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_embedded.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "model_hub.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_hub = model_hub.fit(X_train_embedded, y_train, validation_data=(X_test_embedded, y_test), epochs=10, batch_size=32)\n",
    "\n",
    "# Оцінка моделей\n",
    "loss_scratch, acc_scratch = model_scratch.evaluate(X_test_padded, y_test)\n",
    "loss_hub, acc_hub = model_hub.evaluate(X_test_embedded, y_test)\n",
    "\n",
    "print(f\"Навчання з нуля: точність = {acc_scratch}\")\n",
    "print(f\"Перенесене навчання з embeddings: точність = {acc_hub}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " У першому підході модель використовувала двонаправлений шар LSTM з вбудованим шаром ембедингів, навчаючись з нуля. За допомогою цього підходу ми досягли високу точність на тестових даних – 97%. Модель має такі результаті великій кількості параметрів і здатності адаптуватися до специфіки текстів у даному датасеті.\n",
    "\n",
    "У другому підході використовувалися готові векторні представлення слів із TensorFlow Hub (nnlm-en-dim50). Цей метод дозволив зменшити час навчання та забезпечив хорошу точність – 92%. Попередньо навчені ембедінги ефективно перенесли знання з великих текстових корпусів, що позитивно вплинуло на результати, хоча модель показала трохи нижчу точність, ніж підхід із навчанням з нуля. Таким чином, вибір підходу залежить від наявності ресурсів і часу: навчання з нуля підходить для завдань із достатньою кількістю даних, а перенесене навчання дозволяє швидко отримати прийнятні результати."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
